{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e05e103-2643-478c-9bc4-d3aeb409767a",
   "metadata": {},
   "source": [
    "## Store Data for the streams you want to investigate\n",
    "\n",
    "\n",
    "#### Tweet_processing.\n",
    "This uses utility code stored in `tweetscape-experiments/python/tweet_processing`\n",
    "This utility library will mold as we do more experiments.\n",
    "\n",
    "### Storing Stream Seed Data\n",
    "Data for each group will be stored in the `data/` directory, in a directory titled by group name. \n",
    "\n",
    "**direcotry structure for each group**:\n",
    "* `data/group_name/following.csv`: df of accounts followed by user. Grouped by column `referencer.username`\n",
    "* `data/group_name/tweets.csv`: df of tweets from these users in group. Group by `author.id` or `author.username`\n",
    "* `data/group_name/ref_tweets.csv`: df of tweets referenced in df_tweets. Group by column `referencer.username` \n",
    "\n",
    "\n",
    "This code users twarc to fetch and process data. You can instantiate your twarc client with the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40fb5462-811e-4ea7-a577-b04ef14ae0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tweet_processing import StreamTweetProcessor\n",
    "from twarc import Twarc2, expansions\n",
    "\n",
    "twarc_client = Twarc2(\n",
    "    consumer_key=os.environ[\"consumer_key\"], \n",
    "    consumer_secret=os.environ[\"consumer_secret\"],\n",
    "    access_token=os.environ[\"access_token\"], \n",
    "    access_token_secret=os.environ[\"access_token_secret\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3902b2ac-8979-4773-b248-66c05261a92f",
   "metadata": {},
   "source": [
    "Then, instantiate a StreamTweetProcessor object with the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc94f02a-9e1d-407a-86a3-0ccc514d9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = StreamTweetProcessor(twarc_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2325247-c63c-4142-9937-64c4d86c9109",
   "metadata": {},
   "source": [
    "### Saving Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de492bb-3c36-479e-b15c-c255bf2270f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"longevity-pranab\"\n",
    "usernames = [\"ArtirKel\", \"celinehalioua\", \"LauraDeming\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b520d-1847-481f-a474-483eb2b31900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching accounts followed by ArtirKel\n",
      "fetching accounts followed by celinehalioua\n",
      "fetching accounts followed by LauraDeming\n",
      "pulling tweets for user ArtirKelpulling tweets for user celinehalioua\n",
      "\n",
      "pulling tweets for user LauraDeming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████▋                             | 1/3 [01:42<03:24, 102.36s/it]rate limit exceeded: sleeping 793.6266984939575 secs\n",
      "rate limit exceeded: sleeping 793.3019580841064 secs\n"
     ]
    }
   ],
   "source": [
    "df_following, df_tweets, df_ref_tweets = tp.save_stream_seed_data(group_name, usernames) # saves data in set set of files in dir `data/group_name/*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a75000c-dd2f-42db-ba52-f505980d36ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"referencer.username\" is how to tell which data pertains to which user in the df's df_ref_tweets and df_following\n",
    "df_ref_tweets[\"referencer.username\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996fa61-9b07-44d5-9d29-82b2457fa07f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading Data\n",
    "For actual use, you can load the data with the same object (useful in notebooks where you are actually doing analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa3a7b5-5e35-4eb9-9d2f-97d4baa1c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_following, df_tweets, df_ref_tweets = tp.load_stream_seed_data(group_name) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8876ddf0-4b49-4108-a4f0-25c3d0e46ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_following[\"referencer.username\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07997d6b-4958-4a51-b350-c727815178ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
